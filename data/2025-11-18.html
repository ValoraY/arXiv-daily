<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
  <title>2025-11-18.md</title>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@5/github-markdown.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
  <script>hljs.highlightAll();</script>
  <style>
    body {
      background-color: #fafafa;
      font-family: 'Inter', sans-serif;
      padding: 2rem;
    }
    .markdown-body {
      max-width: 900px;
      margin: auto;
      background: white;
      padding: 2rem;
      border-radius: 12px;
      box-shadow: 0 2px 8px rgba(0,0,0,0.1);
    }
    h1, h2, h3 {
      border-bottom: 1px solid #eaecef;
      padding-bottom: 0.3em;
    }
  </style>
</head>
<body>
  <article class="markdown-body">
    <div id=toc></div>

<h1 id="table-of-contents">Table of Contents</h1>
<ul>
<li><a href="#cs.CV">cs.CV</a> [Total: 1]</li>
</ul>
<div id='cs.CV'></div>

<h1 id="cscv-back">cs.CV <a href="#toc">[Back]</a></h1>
<h3 id="1-doclens-a-tool-augmented-multi-agent-framework-for-long-visual-document-understanding">[1] <a href="https://arxiv.org/abs/2511.11552">DocLens : A Tool-Augmented Multi-Agent Framework for Long Visual Document Understanding</a></h3>
<p><em>Dawei Zhu, Rui Meng, Jiefeng Chen, Sujian Li, Tomas Pfister, Jinsung Yoon</em></p>
<h4 id="tldr">ğŸ§© TL;DR</h4>
<p>æœ¬æ–‡æå‡ºDocLensï¼Œä¸€ç§å·¥å…·å¢å¼ºçš„å¤šæ™ºèƒ½ä½“æ¡†æ¶ï¼Œé€šè¿‡ç±»ä¼¼é•œå¤´çš„æ–¹å¼æ”¾å¤§è¯æ®ï¼Œæœ‰æ•ˆè§£å†³é•¿è§†è§‰æ–‡æ¡£ç†è§£ä¸­çš„è¯æ®å®šä½æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶ç»“åˆGemini-2.5-Proåœ¨MMLongBench-Docå’ŒFinRAGBench-Vä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œç”šè‡³è¶…è¶Šäº†äººç±»ä¸“å®¶ã€‚</p>
<hr />
<h4 id="detailed-summary">ğŸ“˜ Detailed Summary</h4>
<p><strong>Motivation:</strong> ç°æœ‰è§†è§‰è¯­è¨€æ¨¡å‹åœ¨å¤„ç†é•¿è§†è§‰æ–‡æ¡£æ—¶é¢ä¸´è¯æ®å®šä½çš„æ ¹æœ¬æŒ‘æˆ˜ï¼Œå®ƒä»¬éš¾ä»¥æ£€ç´¢ç›¸å…³é¡µé¢å¹¶å¿½ç•¥è§†è§‰å…ƒç´ ä¸­çš„ç»†ç²’åº¦ç»†èŠ‚ï¼Œå¯¼è‡´æ€§èƒ½å—é™å’Œæ¨¡å‹å¹»è§‰é—®é¢˜ã€‚</p>
<p><strong>Method:</strong> DocLensé‡‡ç”¨å·¥å…·å¢å¼ºçš„å¤šæ™ºèƒ½ä½“æ¡†æ¶ï¼Œé¦–å…ˆä»å®Œæ•´æ–‡æ¡£å¯¼èˆªåˆ°ç›¸å…³é¡µé¢ä¸Šçš„ç‰¹å®šè§†è§‰å…ƒç´ ï¼Œç„¶åé‡‡ç”¨é‡‡æ ·-è£å†³æœºåˆ¶ç”Ÿæˆå•ä¸€å¯é çš„ç­”æ¡ˆã€‚</p>
<p><strong>Result:</strong> DocLensåœ¨MMLongBench-Docå’ŒFinRAGBench-Vä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œè¶…è¶Šäº†äººç±»ä¸“å®¶ï¼Œç‰¹åˆ«æ˜¯åœ¨è§†è§‰ä¸­å¿ƒå’Œä¸å¯å›ç­”çš„æŸ¥è¯¢ä¸Šè¡¨ç°å‡ºæ˜æ˜¾ä¼˜åŠ¿ã€‚</p>
<p><strong>Conclusion:</strong> è¯¥ç ”ç©¶è¯æ˜äº†å¢å¼ºå®šä½èƒ½åŠ›åœ¨é•¿æ–‡æ¡£ç†è§£ä¸­çš„é‡è¦æ€§ï¼ŒDocLensæ¡†æ¶åœ¨å¤„ç†è§†è§‰å¯†é›†å’Œå¤æ‚æŸ¥è¯¢æ–¹é¢å±•ç°å‡ºå¼ºå¤§èƒ½åŠ›ï¼Œä¸ºæ–‡æ¡£ç†è§£ç³»ç»Ÿæä¾›äº†æ–°çš„è®¾è®¡èŒƒå¼ã€‚</p>
<hr />
<h4 id="abstract">ğŸ“„ Abstract</h4>
<p>Comprehending long visual documents, where information is distributed across extensive pages of text and visual elements, is a critical but challenging task for modern Vision-Language Models (VLMs). Existing approaches falter on a fundamental challenge: evidence localization. They struggle to retrieve relevant pages and overlook fine-grained details within visual elements, leading to limited performance and model hallucination. To address this, we propose DocLens, a tool-augmented multi-agent framework that effectively ``zooms in'' on evidence like a lens. It first navigates from the full document to specific visual elements on relevant pages, then employs a sampling-adjudication mechanism to generate a single, reliable answer. Paired with Gemini-2.5-Pro, DocLens achieves state-of-the-art performance on MMLongBench-Doc and FinRAGBench-V, surpassing even human experts. The framework's superiority is particularly evident on vision-centric and unanswerable queries, demonstrating the power of its enhanced localization capabilities.</p>
  </article>
</body>
</html>
